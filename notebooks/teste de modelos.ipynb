{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Este notebook é voltado para testes de implantação de um modelo que classifica os generos de uma música utilizando somente sua letra\n",
    "\n",
    "neste documento você encontrara todos os passos básicos de processamento de dados e implementação de um modelo básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import utils\n",
    "#para os testes com Doc2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import multiprocessing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento dos dados\n",
    "### Nesta primeira parte, é utilizada uma função que carrega todos os csvs por gêneros, e concatenam eles para o mesmo DataSet, adicionando a coluna gênero, já em formato numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_csvs(all_files):\n",
    "    df = {}\n",
    "    i = 0\n",
    "    for f in all_files:\n",
    "        df[i] = pd.read_csv(f)\n",
    "        df[i]['genero'] = i + 1\n",
    "        i+= 1\n",
    "    all_pds = pd.concat(df, ignore_index=True)\n",
    "    return all_pds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "C:\\Users\\davia\\Documents\\Projetos\\Finch\\Data\\generos\\bossa_nova.csv\nC:\\Users\\davia\\Documents\\Projetos\\Finch\\Data\\generos\\funk.csv\nC:\\Users\\davia\\Documents\\Projetos\\Finch\\Data\\generos\\gospel.csv\nC:\\Users\\davia\\Documents\\Projetos\\Finch\\Data\\generos\\sertanejo.csv\n"
    }
   ],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "path = 'C:\\\\Users\\\\davia\\\\Documents\\\\Projetos\\\\Finch\\\\Data\\\\generos\\\\'\n",
    "all_files = glob.glob(path + \"\\*.csv\")\n",
    "\n",
    "\n",
    "\n",
    "df_from_each_file = concat_csvs(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aqui começam as funções de limpeza dos dados\n",
    "- São retirados caracteres especiais\n",
    "- espaçamentos duplos são retirados para não criar problemas no split\n",
    "-  o texto é convertido para caixa baixa\n",
    "- são retiradas pontuações\n",
    "- são deletadas as colunas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('\\n',' ')\n",
    "    text = text.replace('  ',' ')\n",
    "    text = text.lower()\n",
    "    text = text.replace(',','')\n",
    "    text = text.replace('?','')\n",
    "    text = text.replace('!','')\n",
    "    text = text.replace('.','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_each_file['lyric'] = df_from_each_file['lyric'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_each_file.drop_duplicates(inplace = True)\n",
    "df_from_each_file = df_from_each_file.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_each_file.to_csv('Data\\\\final.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "text = []\n",
    "\n",
    "for index, row in df_from_each_file.iterrows():\n",
    "    y.append(row[1])\n",
    "    text.append(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aqui utilizamos a funcção TfidfVectorizer do sklearn, com o parametro stop_words para portugues, e tambem, os valores gerados pela função são normalizados e escalados, concluindo a limpeza e transformação dos dados\n",
    "## Tambem é feito o Split dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVec = TfidfVectorizer(stop_words = stopwords.words('portuguese'), sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = countVec.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter= 1000)\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"acurácia da regressão lógica: %s\"%(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(lr, x, y, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aqui começa o teste do modelo de RandomForest\n",
    "\n",
    "## Foi utilizado o método de acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred1 = rf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test,y_pred1)\n",
    "\n",
    "print(\"acurácia da Random Forest: %s\"%(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Em seguida, o modelo de treino do Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genTrain, genTest = train_test_split(df_from_each_file, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "train_tagged = genTrain.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['lyric']), tags=[r.genero]), axis=1)\n",
    "test_tagged = genTest.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['lyric']), tags=[r.genero]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de regressão logistica para utilização do Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train1, X_train1 = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test1, X_test1 = vec_for_learning(model_dbow, test_tagged)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train1, y_train1)\n",
    "y_pred1 = logreg.predict(X_test1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print('acurácia da regressão lógica %s' % accuracy_score(y_test1, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Random Forest para utilização do Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randforest = RandomForestClassifier()\n",
    "randforest.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred1 = randforest.predict(X_test1)\n",
    "accuracy = accuracy_score(y_test1,y_pred1)\n",
    "\n",
    "print(\"acurácia da Random Forest com Doc2Vec: %s\"%(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}